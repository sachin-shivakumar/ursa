import os
import pprint
import subprocess
from typing import Annotated, Any, Dict, List, Literal, Mapping

from langchain_community.tools import DuckDuckGoSearchResults
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_core.tools import tool
from langchain_openai import ChatOpenAI
from langgraph.graph import END, START, StateGraph
from langgraph.prebuilt import InjectedState
from typing_extensions import TypedDict

from ..prompt_library.optimization_prompts import (
    code_generator_prompt,
    discretizer_prompt,
    explainer_prompt,
    extractor_prompt,
    feasibility_prompt,
    math_formulator_prompt,
    solver_selector_prompt,
    verifier_prompt,
)
from ..tools.feasibility_tools import feasibility_check_auto as fca
from ..util.helperFunctions import extract_tool_calls, run_tool_calls
from ..util.optimization_schema import ProblemSpec, SolverSpec
from .base import BaseAgent

# --- ANSI color codes ---
GREEN = "\033[92m"
BLUE = "\033[94m"
RED = "\033[91m"
RESET = "\033[0m"
BOLD = "\033[1m"


class OptimizerState(TypedDict):
    user_input: str
    problem: str
    problem_spec: ProblemSpec
    solver: SolverSpec
    code: str
    problem_diagnostic: List[Dict]
    summary: str


class OptimizationAgent(BaseAgent):
    def __init__(self, llm="OpenAI/gpt-4o", *args, **kwargs):
        super().__init__(llm, *args, **kwargs)
        self.extractor_prompt = extractor_prompt
        self.explainer_prompt = explainer_prompt
        self.verifier_prompt = verifier_prompt
        self.code_generator_prompt = code_generator_prompt
        self.solver_selector_prompt = solver_selector_prompt
        self.math_formulator_prompt = math_formulator_prompt
        self.discretizer_prompt = discretizer_prompt
        self.feasibility_prompt = feasibility_prompt
        self.tools = [fca]  # [run_cmd, write_code, search_tool, fca]
        self.llm = self.llm.bind_tools(self.tools)
        self.tool_maps = {
            (getattr(t, "name", None) or getattr(t, "__name__", None)): t
            for i, t in enumerate(self.tools)
        }

        self._action = self._build_graph()

    # Define the function that calls the model
    def extractor(self, state: OptimizerState) -> OptimizerState:
        new_state = state.copy()
        new_state["problem"] = self.llm.invoke([
            SystemMessage(content=self.extractor_prompt),
            HumanMessage(content=new_state["user_input"]),
        ]).content

        new_state["problem_diagnostic"] = []

        print("Extractor:\n")
        pprint.pprint(new_state["problem"])
        return new_state

    def formulator(self, state: OptimizerState) -> OptimizerState:
        new_state = state.copy()

        llm_out = self.llm.with_structured_output(
            ProblemSpec, include_raw=True
        ).invoke([
            SystemMessage(content=self.math_formulator_prompt),
            HumanMessage(content=state["problem"]),
        ])
        new_state["problem_spec"] = llm_out["parsed"]
        new_state["problem_diagnostic"].extend(
            extract_tool_calls(llm_out["raw"])
        )

        print("Formulator:\n")
        pprint.pprint(new_state["problem_spec"])
        return new_state

    def discretizer(self, state: OptimizerState) -> OptimizerState:
        new_state = state.copy()

        llm_out = self.llm.with_structured_output(
            ProblemSpec, include_raw=True
        ).invoke([
            SystemMessage(content=self.discretizer_prompt),
            HumanMessage(content=state["problem"]),
        ])
        new_state["problem_spec"] = llm_out["parsed"]
        new_state["problem_diagnostic"].extend(
            extract_tool_calls(llm_out["raw"])
        )

        print("Discretizer:\n")
        pprint.pprint(new_state["problem_spec"])

        return new_state

    def tester(self, state: OptimizerState) -> OptimizerState:
        new_state = state.copy()

        llm_out = self.llm.bind(tool_choice="required").invoke([
            SystemMessage(content=self.feasibility_prompt),
            HumanMessage(content=str(state["code"])),
        ])

        tool_log = run_tool_calls(llm_out, self.tool_maps)
        new_state["problem_diagnostic"].extend(tool_log)

        print("Feasibility Tester:\n")
        for msg in new_state["problem_diagnostic"]:
            msg.pretty_print()
        return new_state

    def selector(self, state: OptimizerState) -> OptimizerState:
        new_state = state.copy()

        llm_out = self.llm.with_structured_output(
            SolverSpec, include_raw=True
        ).invoke([
            SystemMessage(content=self.solver_selector_prompt),
            HumanMessage(content=str(state["problem_spec"])),
        ])
        new_state["solver"] = llm_out["parsed"]

        print("Selector:\n ")
        pprint.pprint(new_state["solver"])
        return new_state

    def generator(self, state: OptimizerState) -> OptimizerState:
        new_state = state.copy()

        new_state["code"] = self.llm.invoke([
            SystemMessage(content=self.code_generator_prompt),
            HumanMessage(content=str(state["problem_spec"])),
        ]).content

        print("Generator:\n")
        pprint.pprint(new_state["code"])
        return new_state

    def verifier(self, state: OptimizerState) -> OptimizerState:
        new_state = state.copy()

        llm_out = self.llm.with_structured_output(
            ProblemSpec, include_raw=True
        ).invoke([
            SystemMessage(content=self.verifier_prompt),
            HumanMessage(content=str(state["problem_spec"]) + state["code"]),
        ])
        new_state["problem_spec"] = llm_out["parsed"]
        if hasattr(llm_out, "tool_calls"):
            tool_log = run_tool_calls(llm_out, self.tool_maps)
            new_state["problem_diagnostic"].extend(tool_log)

        print("Verifier:\n ")
        pprint.pprint(new_state["problem_spec"])
        return new_state

    def explainer(self, state: OptimizerState) -> OptimizerState:
        new_state = state.copy()

        new_state["summary"] = self.llm.invoke([
            SystemMessage(content=self.explainer_prompt),
            HumanMessage(content=state["problem"] + str(state["problem_spec"])),
            *state["problem_diagnostic"],
        ]).content

        print("Summary:\n")
        pprint.pprint(new_state["summary"])
        return new_state

    def _build_graph(self):
        graph = StateGraph(OptimizerState)

        self.add_node(graph, self.extractor, "Problem Extractor")
        self.add_node(graph, self.formulator, "Math Formulator")
        self.add_node(graph, self.selector, "Solver Selector")
        self.add_node(graph, self.generator, "Code Generator")
        self.add_node(graph, self.verifier, "Verifier")
        self.add_node(graph, self.explainer, "Explainer")
        self.add_node(graph, self.tester, "Feasibility Tester")
        self.add_node(graph, self.discretizer, "Discretizer")

        graph.add_edge(START, "Problem Extractor")
        graph.add_edge("Problem Extractor", "Math Formulator")
        graph.add_conditional_edges(
            "Math Formulator",
            should_discretize,
            {"discretize": "Discretizer", "continue": "Solver Selector"},
        )
        graph.add_edge("Discretizer", "Solver Selector")
        graph.add_edge("Solver Selector", "Code Generator")
        graph.add_edge("Code Generator", "Feasibility Tester")
        graph.add_edge("Feasibility Tester", "Verifier")
        graph.add_conditional_edges(
            "Verifier",
            should_continue,
            {"continue": "Explainer", "error": "Problem Extractor"},
        )
        graph.add_edge("Explainer", END)

        return graph.compile()

    def _invoke(
        self, inputs: Mapping[str, Any], recursion_limit: int = 100000, **_
    ):
        config = self.build_config(
            recursion_limit=recursion_limit, tags=["graph"]
        )
        if "user_input" not in inputs:
            try:
                inputs["user_input"] = inputs["messages"][0].content
            except KeyError:
                raise ("'user_input' is a required argument")

        return self._action.invoke(inputs, config)


#########  try:
#########      png_bytes = compiled_graph.get_graph().draw_mermaid_png()
#########      img = mpimg.imread(io.BytesIO(png_bytes), format='png')  # decode bytes -> array

#########      plt.imshow(img)
#########      plt.axis('off')
#########      plt.show()
#########  except Exception as e:
#########      # This requires some extra dependencies and is optional
#########      print(e)
#########      pass


@tool
def run_cmd(query: str, state: Annotated[dict, InjectedState]) -> str:
    """
    Run a commandline command from using the subprocess package in python

    Args:
        query: commandline command to be run as a string given to the subprocess.run command.
    """
    workspace_dir = state["workspace"]
    print("RUNNING: ", query)
    try:
        process = subprocess.Popen(
            query.split(" "),
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True,
            cwd=workspace_dir,
        )

        stdout, stderr = process.communicate(timeout=60000)
    except KeyboardInterrupt:
        print("Keyboard Interrupt of command: ", query)
        stdout, stderr = "", "KeyboardInterrupt:"

    print("STDOUT: ", stdout)
    print("STDERR: ", stderr)

    return f"STDOUT: {stdout} and STDERR: {stderr}"


@tool
def write_code(
    code: str, filename: str, state: Annotated[dict, InjectedState]
) -> str:
    """
    Writes python or Julia code to a file in the given workspace as requested.

    Args:
        code: The code to write
        filename: the filename with an appropriate extension for programming language (.py for python, .jl for Julia, etc.)

    Returns:
        Execution results
    """
    workspace_dir = state["workspace"]
    print("Writing filename ", filename)
    try:
        # Extract code if wrapped in markdown code blocks
        if "```" in code:
            code_parts = code.split("```")
            if len(code_parts) >= 3:
                # Extract the actual code
                if "\n" in code_parts[1]:
                    code = "\n".join(code_parts[1].strip().split("\n")[1:])
                else:
                    code = code_parts[2].strip()

        # Write code to a file
        code_file = os.path.join(workspace_dir, filename)

        with open(code_file, "w") as f:
            f.write(code)
        print(f"Written code to file: {code_file}")

        return f"File {filename} written successfully."

    except Exception as e:
        print(f"Error generating code: {str(e)}")
        # Return minimal code that prints the error
        return f"Failed to write {filename} successfully."


search_tool = DuckDuckGoSearchResults(output_format="json", num_results=10)
# search_tool = TavilySearchResults(max_results=10, search_depth="advanced", include_answer=True)


# A function to test if discretization is needed
def should_discretize(
    state: OptimizerState,
) -> Literal["Discretize", "continue"]:
    cons = state["problem_spec"]["constraints"]
    decs = state["problem_spec"]["decision_variables"]

    if any("infinite-dimensional" in t["tags"] for t in cons) or any(
        "infinite-dimensional" in t["type"] for t in decs
    ):
        # print(f"Problem has infinite-dimensional constraints/decision variables. Needs to be discretized")
        return "discretize"

    return "continue"


# Define the function that determines whether to continue or not
def should_continue(state: OptimizerState) -> Literal["error", "continue"]:
    spec = state["problem_spec"]
    try:
        status = spec["status"].lower()
    except KeyError:
        status = spec["spec"]["status"].lower()
    if "VERIFIED".lower() in status:
        return "continue"
    # Otherwise if there is, we continue
    else:
        return "error"


def main():
    model = ChatOpenAI(
        model="gpt-4o", max_tokens=10000, timeout=None, max_retries=2
    )
    execution_agent = OptimizationAgent(llm=model)
    # execution_agent = execution_agent.bind_tools(feasibility_checker)
    problem_string = """
    Solve the following optimal power flow problem
    System topology and data:
        - Three buses (nodes) labeled 1, 2 and 3.
        - One generator at each bus; each can only inject power (no negative output).
        - Loads of 1 p.u. at bus 1, 2 p.u. at bus 2, and 4 p.u. at bus 3.
        - Transmission lines connecting every pair of buses, with susceptances (B):
            - Line 1â€“2: Bâ‚â‚‚ = 10
            - Line 1â€“3: Bâ‚â‚ƒ = 20
            - Line 2â€“3: Bâ‚‚â‚ƒ = 30

    Decision variables:
        - Voltage angles Î¸â‚, Î¸â‚‚, Î¸â‚ƒ (in radians) at buses 1â€“3.
        - Generator outputs Páµâ‚, Páµâ‚‚, Páµâ‚ƒ â‰¥ 0 (in per-unit).

    Reference angle:
        - To fix the overall angleâ€shift ambiguity, we set Î¸â‚ = 0 (â€œslackâ€ or reference bus).

    Objective:
        - Minimize total generation cost with
            - ğ‘1 = 1
            - ğ‘2 = 10
            - ğ‘3 = 100

    Lineâ€flow limits
        - Lines 1-2 and 1-3 are thermalâ€limited to Â±0.5 p.u., line 2-3 is unconstrained.
    
    In words:
    We choose how much each generator should produce (at non-negative cost) and the voltage angles at each bus (with bus 1 set to zero) so that supply exactly meets demand, flows on the critical lines donâ€™t exceed their limits, and the total cost is as small as possible. 
    Use the tools at your disposal to check if your formulation is feasible.
    """
    inputs = {"user_input": problem_string}
    result = execution_agent.invoke(inputs)
    print(result["messages"][-1].content)
    return result


if __name__ == "__main__":
    main()


#         minâ¡ ğ‘ƒğ‘”â€…â€Šğ‘1*ğ‘ƒ1 + ğ‘2 * ğ‘ƒ2 + ğ‘3 * ğ‘ƒ3
